# ML Modely - Technick√° dokumentace

## P≈ôehled ML infrastruktury

Cell Segmentation Hub vyu≈æ√≠v√° 2 pokroƒçil√© deep learning modely pro s√©mantickou segmentaci bunƒõƒçn√Ωch struktur, oba implementovan√© v PyTorch a optimalizovan√© pro spheroid detekci na rozli≈°en√≠ 1024√ó1024.

## üìä P≈ôehled v√Ωkonu model≈Ø (Aktualizov√°no 2025-08-31)

| Model            | Parametry | Rozli≈°en√≠ | Inference ƒças | Throughput | P95 Latence | Batch Size | Doporuƒçen√© pou≈æit√≠ |
| ---------------- | --------- | --------- | ------------- | ---------- | ----------- | ---------- | ------------------ |
| **HRNet**        | ~66M      | 1024√ó1024 | **~0.2s**     | 5.5 img/s  | <0.3s       | 8 (opt)    | Vysok√° propustnost |
| **CBAM-ResUNet** | ~64M      | 1024√ó1024 | **~0.3s**     | 3.0 img/s  | <0.7s       | 2 (opt)    | Maxim√°ln√≠ p≈ôesnost |

**Testov√°no na**: NVIDIA RTX A5000 (24GB VRAM), produkƒçn√≠ prost≈ôed√≠ s dynamic batching

## üß† Implementovan√© modely

### 1. HRNetV2 (High-Resolution Network V2)

- **Soubor**: `models/hrnet.py`
- **T≈ô√≠da**: `HRNetV2`
- **Parametry**: ~66M
- **Architektura**: Multi-resolution parallel branches
- **Specialita**: Zachov√°n√≠ vysok√©ho rozli≈°en√≠ skrz celou s√≠≈•

#### Kl√≠ƒçov√© vlastnosti:

```python
# Inicializace
model = HRNetV2(n_class=1, use_instance_norm=True)

# Architektura
- Stem network: Conv3x3 ‚Üí Conv3x3 (64 channels)
- Stage 1: Bottleneck blocks (256 channels)
- Stage 2: Parallel branches [64, 128]
- Stage 3: Parallel branches [64, 128, 256]
- Stage 4: Parallel branches [64, 128, 256, 512]
- Final: Fusion + Classification head
```

#### V√Ωkonnost (Produkce 2025-08-31):

- **Inference ƒças**: ~0.2s (GPU, 1024x1024)
- **Throughput**: 5.5 images/second
- **P95 Latence**: <0.3s
- **Batch Size**: 8 (optim√°ln√≠), 12 (maxim√°ln√≠)
- **Pamƒõ≈•**: ~1.2GB VRAM p≈ôi batch size 8
- **Doporuƒçen√Ω threshold**: 0.4-0.6
- **Dynamic Batching**: Ano, 5ms queue delay

---

### 2. CBAM-ResUNet (Channel & Spatial Attention ResUNet)

- **Soubor**: `models/cbam_resunet.py`
- **T≈ô√≠da**: `ResUNetCBAM`
- **Parametry**: ~64M
- **Architektura**: U-Net + ResNet blocks + CBAM (Channel & Spatial Attention)
- **Specialita**: Nejvy≈°≈°√≠ p≈ôesnost d√≠ky dual attention mechanismu

#### Kl√≠ƒçov√© vlastnosti:

```python
# Inicializace
model = ResUNetCBAM(in_channels=3, out_channels=1, features=[64, 128, 256, 512])

# Architektura
- Encoder: ResidualBlock s CBAM attention
- Bottleneck: Double residual blocks
- Decoder: Transposed convolutions + skip connections
- Features: [64, 128, 256, 512] channels
- CBAM: Channel attention ‚Üí Spatial attention
```

#### V√Ωkonnost (Produkce 2025-08-31):

- **Inference ƒças**: ~0.3s (GPU, 1024x1024)
- **Throughput**: 3.0 images/second
- **P95 Latence**: <0.7s
- **Batch Size**: 2 (optim√°ln√≠), 4 (maxim√°ln√≠)
- **Pamƒõ≈•**: ~900MB VRAM p≈ôi batch size 2
- **Doporuƒçen√Ω threshold**: 0.4-0.6
- **Dynamic Batching**: Ano, 5ms queue delay

---

## üîß Model Loading Pipeline

### ModelLoader t≈ô√≠da

```python
from ml.model_loader import ModelLoader

# Inicializace
loader = ModelLoader(base_path="./segmentation")

# Naƒçten√≠ modelu
model = loader.load_model("hrnet", use_finetuned=True)

# Predikce
result = loader.predict(image, "hrnet", threshold=0.5)
```

### Checkpoint form√°ty

Podporovan√© form√°ty ulo≈æen√Ωch model≈Ø:

```python
# Standardn√≠ PyTorch checkpoint
{
    'model_state_dict': state_dict,
    'epoch': int,
    'optimizer_state_dict': optimizer_state,
    'loss': float,
    'config': dict
}

# Pouze weights
state_dict

# S training metadaty
{
    'state_dict': state_dict,
    'args': argparse.Namespace,
    'best_score': float
}
```

## üìä Preprocessing Pipeline

### Vstupn√≠ transformace

```python
from PIL import Image
import numpy as np
import torch

def preprocess_image(image: Image.Image, target_size=(1024, 1024)):
    # 1. Konverze na RGB
    if image.mode != 'RGB':
        image = image.convert('RGB')

    # 2. Resize s Lanczos interpolac√≠
    try:
        # Pillow 10.0.0+
        image = image.resize(target_size, Image.Resampling.LANCZOS)
    except AttributeError:
        # Pillow < 10.0.0
        image = image.resize(target_size, Image.LANCZOS)

    # 3. Normalizace [0, 1]
    image_np = np.array(image).astype(np.float32) / 255.0

    # 4. Channel-first format + batch dimension
    tensor = torch.from_numpy(image_np.transpose(2, 0, 1)).unsqueeze(0)

    return tensor
```

### Data augmentace (tr√©nov√°n√≠)

```python
import albumentations as A

transform = A.Compose([
    A.HorizontalFlip(p=0.5),
    A.VerticalFlip(p=0.5),
    A.RandomRotate90(p=0.5),
    A.ShiftScaleRotate(shift_limit=0.1, scale_limit=0.2, rotate_limit=45, p=0.5),
    A.ElasticTransform(alpha=120, sigma=6, p=0.3),
    A.GridDistortion(num_steps=5, distort_limit=0.3, p=0.3),
    A.OpticalDistortion(distort_limit=0.3, shift_limit=0.1, p=0.3),
    A.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.3, hue=0.1, p=0.5),
    A.GaussNoise(var_limit=(10, 50), p=0.3),
    A.GaussianBlur(blur_limit=3, p=0.3),
])
```

## üéØ Postprocessing Pipeline

### Mask ‚Üí Polygons konverze

```python
def postprocess_mask(mask: torch.Tensor, original_size: tuple, threshold: float):
    # 1. Sigmoid aktivace
    mask = torch.sigmoid(mask).squeeze().cpu().numpy()

    # 2. Resize na p≈Øvodn√≠ velikost
    mask_resized = cv2.resize(mask, original_size, interpolation=cv2.INTER_LINEAR)

    # 3. Binarizace
    binary_mask = (mask_resized > threshold).astype(np.uint8)

    # 4. Hled√°n√≠ kontur
    contours, _ = cv2.findContours(binary_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

    # 5. Filtrace a aproximace
    polygons = []
    for contour in contours:
        if cv2.contourArea(contour) > 100:  # Min. area
            epsilon = 0.002 * cv2.arcLength(contour, True)
            approx = cv2.approxPolyDP(contour, epsilon, True)

            if len(approx) >= 3:
                polygon_points = [[float(x), float(y)] for x, y in approx.reshape(-1, 2)]
                polygons.append({
                    "id": f"polygon_{len(polygons) + 1}",
                    "points": polygon_points,
                    "type": "external",
                    "class": "spheroid",
                    "confidence": float(mask.max())
                })

    return polygons
```

## ‚ö° Optimalizace v√Ωkonu

### GPU Acceleration

```python
# Automatick√° detekce GPU
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

# Move model and input to device
model = model.to(device)
input_tensor = input_tensor.to(device)

# Mixed precision inference (rychlej≈°√≠ na GPU)
if device.type == 'cuda':
    with torch.cuda.amp.autocast():
        output = model(input_tensor)
else:
    # CPU inference without autocast
    output = model(input_tensor)
```

### Batch Processing

```python
def batch_predict(images: List[PIL.Image], batch_size=4):
    """Zpracov√°n√≠ v√≠ce obr√°zk≈Ø najednou"""
    results = []

    for i in range(0, len(images), batch_size):
        batch = images[i:i+batch_size]
        batch_tensor = torch.stack([preprocess_image(img) for img in batch])

        with torch.no_grad():
            batch_output = model(batch_tensor)

        for j, output in enumerate(batch_output):
            result = postprocess_mask(output, batch[j].size, threshold)
            results.append(result)

    return results
```

### Model Quantization (experimental)

```python
# Post-training dynamic quantization (only supports Linear layers)
model_quantized = torch.quantization.quantize_dynamic(
    model, {torch.nn.Linear}, dtype=torch.qint8
)

# For Conv2d layers, use static quantization instead:
# model.qconfig = torch.quantization.get_default_qconfig('fbgemm')
# torch.quantization.prepare(model, inplace=True)
# # Run calibration with representative data
# torch.quantization.convert(model, inplace=True)
```

## üìà Metriky a evaluace

### Podporovan√© metriky

```python
# Pixel-wise metriky
- IoU (Intersection over Union)
- Dice Coefficient
- Pixel Accuracy
- F1 Score

# Object-level metriky
- Average Precision (AP)
- Mean IoU per object
- Detection Rate
- False Positive Rate
```

### Benchmark v√Ωsledky

```yaml
Dataset: Spheroid Segmentation Test Set (100 images)

HRNetV2:
  mIoU: 0.847
  Dice: 0.916
  F1: 0.923
  AP@0.5: 0.891

ResUNet Small:
  mIoU: 0.798
  Dice: 0.878
  F1: 0.889
  AP@0.5: 0.851

Advanced ResUNet:
  mIoU: 0.859
  Dice: 0.925
  F1: 0.931
  AP@0.5: 0.902
```

## üîß Troubleshooting

### ƒåast√© probl√©my a ≈ôe≈°en√≠

#### 1. OOM (Out of Memory) chyby

```python
# ≈òe≈°en√≠: Men≈°√≠ batch size nebo input rozli≈°en√≠
input_size = (256, 256)  # M√≠sto (512, 512)
batch_size = 1

# Gradient checkpointing (pouze tr√©nov√°n√≠)
model.gradient_checkpointing = True
```

#### 2. Pomal√° inference

```python
# Optimalizace:
model.eval()  # Evaluation mode
torch.backends.cudnn.benchmark = True  # CuDNN optimization
with torch.no_grad():  # Disable gradients
    output = model(input)
```

#### 3. ≈†patn√© v√Ωsledky segmentace

```python
# Debugging kroky:
1. Zkontrolovat vstupn√≠ normalizaci
2. Ovƒõ≈ôit spr√°vn√Ω threshold (0.3-0.8)
3. Vizualizovat raw model output
4. Zkontrolovat preprocessing pipeline
5. Testovat na zn√°m√Ωch good cases
```

#### 4. Model loading chyby

```python
# Strict=False pro ƒç√°steƒçn√© naƒçten√≠
model.load_state_dict(checkpoint, strict=False)

# Mapov√°n√≠ na CPU pokud nen√≠ GPU
checkpoint = torch.load(path, map_location='cpu')
```

## üöÄ Deployment tipy

### Produkƒçn√≠ optimalizace

```python
# 1. Model export pro deployment
torch.jit.script(model).save("model_scripted.pt")

# 2. ONNX export pro cross-platform
torch.onnx.export(model, dummy_input, "model.onnx")

# 3. TensorRT optimalizace (NVIDIA GPU)
import torch_tensorrt

# Create Input descriptors instead of raw tensors
inputs = [
    torch_tensorrt.Input(
        shape=(1, 3, 1024, 1024),  # Batch size, channels, height, width
        dtype=torch.float32,
        device=torch.device("cuda")
    )
]

optimized_model = torch_tensorrt.compile(model, inputs=inputs)
```

### Docker deployment

```dockerfile
# Multi-stage build pro men≈°√≠ image
FROM python:3.10-slim

WORKDIR /app
COPY requirements.txt .
RUN pip install -r requirements.txt

COPY models/ ./models/
COPY weights/ ./weights/
COPY api/ ./api/

CMD ["python", "api/main.py"]
```

---

**Pozn√°mka**: V≈°echny modely jsou tr√©novan√© na propriet√°rn√≠m datasetu spheroid≈Ø a optimalizovan√© pro bunƒõƒçnou segmentaci na 1024√ó1024 rozli≈°en√≠. Pro jin√© aplikace m≈Ø≈æe b√Ωt pot≈ôebn√Ω fine-tuning nebo retraining.

**Zmƒõny v implementaci**: PSPNet byl odstranƒõn z implementace podle po≈æadavk≈Ø u≈æivatele. Syst√©m nyn√≠ podporuje pouze 3 modely: HRNet, ResUNet Small a Advanced ResUNet.

_Dokumentace aktualizov√°na: 2025-08-14_
